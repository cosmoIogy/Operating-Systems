Lecture #6 - Concurrency-Mutual Exclusion 

Race Condition
--
    - occurs when multiple processes or threads read and wite items so that the finals result depends on order of execution 

    Examples: fork-race.c 

    #include <stdio.h>
    #include <stdlin.h>
    #include <unistd.h>
    #include <sys/types.h>
    #include <fcntl.h>

    int main() {
        char c;
        pid_t pid;

        int fd = open("test.txt", 0_RDWR);
        if (fd == -1){
            perror("error opening the file\n");
        }
        read(fd, &c, 1);
        printf("before the fork %c\n", c);

        pid = fork();
        if (pid == -1){
            perror("error fork()\n");
        }
        if (pid == 0){ // child
            read(fd, &c, 1);
            printf("child: %c\n", c);
        } else { //parent 
            read(fd, &c, 1);
            printf("parent: %c\n", c);
        }
        return 0;
    }

    ex: fork-race-fixed.c
    #include <stdio.h>
    #include <stdlin.h>
    #include <unistd.h>
    #include <sys/types.h>
    #include <fcntl.h>

    int main(){
        char c;
        pid_t pid;
        
        int fd = open("test.txt", 0_RDWR);
        if (fd == -1){
            perror("error opening the file\n");
            exit(1);
        }

        // read first char 
        if (read(fd, &c, 1) != 1) {
            perror("error opening the file\n");
            close(fd);
            exit(1);
        }
        printf("before fork: %c\n", c);

        pid = fork();
        if (pid == -1){
            perror("error in forking process");
            close(fd);
            exit(1);
        }

        if (pid == 0) { //child
            int child_fd = open("test.txt", 0_RDWR);
            if (child_fd == -1){
                perror("child error opening the file");
                exit(1);
            }
            if (lseek(child_fd, 1, SEEK_SET) == -1){
                perror("child lseek error");
                close(child_fd);
                exit(1);
            }
            if (read(child_fd &c, 1) == 1){
                printf("Child read: %c\n", c);
            } else {
                perror("child read error");
            }
            close(child_fd);
        } else { //parent
            if (lseek(child_fd, 1, SEEK_SET) == -1){
                perror("child lseek error");
                close(child_fd);
                exit(1);
        }
            if (read(fd, &c, 1) == 1){
                    printf("parent read: %c\n", c);
            } else {
                perror ("parent read error");
            }
            close(fd);
        }
        return 0;
    }

Concurrency Terms 
--

Atomic Operation - operations that executes as an indivisble unit, meaning it either completes fully or not at all, with no intermediate state
visible to other processes 

Critical Section - a part of program that accesses shared resources and must be executed simultaneously by multiple processes 

Deadlock - a situation where two or more processes cannot proceed because each is waiting for the other to take action 

Livelock - a scenario where processes continously change theirs states in response to each other but make no actual progress 

Mutal exclusion - a principle ensuring that when one process accesses a shared resouce, no other process can do so simultaneously

Race condition - a situation where multiple processes access and modify shared data, with the outcome depending on their execution time 

Starvation - a condition where a process is indefinitely denied access to resources because higher-priority processes are continuously favored


Critical section problem 
--
- a system consists of n proccesses, each having a critical section where shared resources are accessed 

- only one process can be in the critical section at a time to prevent conflicts 

- typically a software issue. the idea is to prevent race conditions and ensure mutal exclusions

- each process must request permissions before entering the critical section (known as the entry section), and finally exit before proceeding
to remainder section 

while (1){
    enter section 
        critical section (manipulate a shared resource in some way)
    exit section
        remainder section
}

exit section - refers to the critical section being done and another thread may now manipulate a shared resources 

remainder section - is code that does not require synchronization and can be executed without holding a lock 

requirements for a solution to critical section problem:
--
1. mutual exlusion - only one process can be in its critical section at a time; no two processes should execute their ciritcal section simultaneously
2. progress - if no process is in the critical section and some processes want to enter, a process must be selected within a finite time to 
proceed; section cannot be postponed indefinitely
3. bounded-waiting - a limit must be set on how many times other processes can enter critical section before waiting process gets its turn,
preventing indefinite blocking (starvation)

software solutions:
--
(1) two process solution
    - load and store operations are assumed to be atomic, meaning they cannot be interrupted 
    - the processes (P0(i) and P1(i))
        - the variable (turn) indicates which process is allowed to enter the critical section 
    - initally, set turn to 0 (i) 

    int turn = i;
    while (1){
        while (turn == j); // busy waiting or spin waiting 
            // critical section 
        turn = i;
            // remainder section 
    } 

does this solution work?
    - mutual exlusion is preserved 
        - process only enters critical if its their turn 

    - progress requirement?
        - no does not satisfy progress requirement, j is stuck waiting -> no access to critical section (based on infinite while loop
        when turn == j)

    - bounded-waiting requirement? 
        - no does not satisfy bounded-waiting requiremen 
        - if one process fails, one process will be permanently blocked 

(2) two process share a vector: 
    - boolean flag[2];
    - the flag indicates 

    while (1){
        while (flag[j]);
        flag[i] = true // entry point 
            // critical section 
        flag[j] = false; // exit point 
            // remainder section 
    }

does this solution work?
    what about these sequence of events:
        - Pi executes the while loop and finds flag[j] = false 
        - Pj executes the while loop and finds flag[i] = false 
            - both Pi and Pj are entered into the critical section 

        due to the above scenario, this solution may not work 

(3) peterson's algorithm 
        - two process solution: ensure mutual exlusion for two processes 
        - shared variables:
            - int turn; // determines whos turn it is to enter critical section 
            - boolean flag[2]; // indicates if a process is ready to enter critical section 

        - each process set its respective flags turn when it wants to enter 
        - turn variables determines which process gets priority 
        - a process can enter critical section only if the other process is not ready (flag = false) or it is its turn

    
    int turn;
    bool flag[2];

    while(1){
        flag[i] = true;
        turn = j;
        while (flag[j] && turn == j);
            /* critical section */
        flag[i] = false;
            /* remainder section */
    }

    Does this work?
        - mutual exlusion is preserved
        - progress requirement is satisfied; if no process in critical, one will proceed
        - bounded-waiting requirement is met; no process is indefinitely blocked 

Petersons Solution and Modern Architecture 
--
    - petersons solution is guranteed to work on modern architectures because:
        - modern processors and compilers reorder operations to optimize performance, potientally breaking the algorithms correctness 
    
    - understanding its limitations helps in recognizing race conditions and improving synchronization techniques 
        - single-threaded execution - unaffected in the order of execution (remains consistent)

        - multi-threaded execution - results in unexpected or inconsistent behavior due to insturction ordering (shuffling)

    examples -> modern architecture 

    two threads that share data:
        bool flag = false;
        int x = 0;

        thread 1:

        while(!flag):
        print(x);

        thread 2:

        x = 100;
        flag = true;

        what is the expected output? 100

        since the variable x and flag are independent, they could reordered for optimization

        reordered thread 2:

        flag = true;
        x = 100;

        the output may now be 0 

    memory barrier
    --
        - memory models define how a computer manages memory visibility across different processors in multi-threaded environments 

        - types of memory models:
            - strongly ordered - memory changes by one processor and is immediately visible to all others 

            - weakly ordered - memory changes by one processor may not immediately be visible to all other processors 

        memory barrier - a special instruction that ensures all memory modifications propogated are visible to all processors 

    memory barrier instructions 
    --
    purpose: ensure all load and store operations are completed before any future load or store operations 

    effect on instruction reorder:
        - even if instructions are reordered for optimization, the memory barrier guarantees that all previous stored operations are 
        completed and visible to other processors before new operations begin 

     thread 1:

        while(!flag):
        memory_barrier();
        print(x);

        thread 2:

        x = 100;
        memory_barrier();
        flag = true;

concurrency mechanism 
--
    - semaphore - an integer value used for signaling among processes 
    - only three operations:
        - initialize - zero or positive 
        - decrement - may result in the blocking of a process 
        - increment - may result in the unblocking of a process 

    - binary semaphore - a semaphore that takes only the values 0 or 1 

    - mutex - similar to a binary semaphore. major difference is that the process that locks mutex (sets it to 0) must be the one that unblocks 
    the mutex (sets the value to 1)

    - spinlocks - mutual exlusion mechanism in which a process executes an infinite loop waiting for the value of a lock variable to indicate 
    avaliablity 

semaphore 
--
only way to manipulate is via three operations: 
    1. initalized to a nonnegative number
    2. the semWait function decrements a semaphore value when called 
    3. the semSignal/semPost operation increments semaphore value when called 

if the value is zero:
    can be considered a blocked state for now, but sometimes this allows to run (decrementing the semaphore causing a negative value)
        - every new process that called semWait will cause semaphore to continously 

        negative values = number of processes ready to run (stuck in a queue waiting)

    types of semaphore(queue):
        there are two types for both binary and counting semaphores when talking about a queue: 


        - semWait and semSignal opeartions should be implemented as atomic primitives 
        - can be implemented as software and hardware 
        - mutual exclusion - only one process may manipulate a semaphore with either a semWait or semSignal operation 
        - *** for a signal-process system, it is possible to inhibit interrupts for durations of a semWait or semSingal 

Synchronization of Hardware 
--
    - many systems do provide hardware support for implementing critical section code 

    - one case is to disable interrupts specifically on a uniprocessor system, stop code from preempting execution 
        - this is inefficent for multiprocessor systems -> some processors may end up being idle  

    - two different examples of hardware insturctions that allow us to implement critical section concept:
        - test-and-test 
        - compare-and-swap 

    ** classified as special hardware instructions 
        - allow us to to either test and modify 

    test_and_set instruction 

    boolean test_and_set(boolean *target){
        boolean rv = *target;
        *target = true;
        returnn rv;
    }

    - used to write a variable and read its old value as a single indivisble step 
        - often used in locking mechanisms for synchronization in concurrent programming 

    - typically executed atomically, meaning if two processes are executing this function at the same time they will do so sequentially
    - return original value of passed parameter and set the new value of passed param to true 

    could have a shared variable called "lock" init'd to false (mutex) 

    do {
        while (test_and_set(&lock)); // do nothing 
        /* critical section */
        lock = false; 
        /* remainder section */
    } while(1); 

    ** busy-waiting or spinlock - process is repeatedly checking to see if the lock is avaliable (cause some load on the CPU) 
        - main efficient use-case: critical section is short and wait times are expected to be smaller 

compare_and_swap instruction 
--
    int compare_and_swap(int *value, int expected, int new_value){
        int temp = *value;
        if (*value == expected) *value = new_value;
        return temp; 
    }

    - executed atomically 
    - returns the original value of passed parameter 
    - it attempts to write new_value into *value but only if current value is the expected value 
        - it is a critical operation in implementing lock-free data structures and algorithm, as it allows coordination between threads 
        without the need for mutex locks 

    while (true){
        while (test_and_set(&lock, 0, 1)); // do nothing
        /* critical section */
        lock = false; 
        /* remainder section */
    }

    example of synchronization:
        - producer-consumer synchronization problem 
        - readers-writes synchronization problem 
        - dining-philospher synchronization problem 

producer-consumer problem 
--
    - producers generate and add data to a shared buffer 
    - a single consumer removes data from buffer one item at a time 
    - only one producer or comsumer can access the buffer at any given time 

    the problems:
    - prevent overfilling - the producer should not add data if the buffer is full 
    - prevent underflow - the consumer should not remove dat if the buffer is empty 

    stuct sbuf_t{
        int *buff; // buffer array 
        int n; // max number of slots 
        int front;
        int rear;
        sem_t mutex; // like a binary semaphore -> 0,1 
        sem_t slots; // counting semaphore -> 0, ..., n 
        sem_t items; // counting semaphore -> 0, ..., n 
    }

    synchronization via semaphore:
        - mutex initalized to 1 -> ensure mutual exclusion so only one process (producer/consumer) accesses the buffer at a time 

        - items (init'd to 0) -> tracks the number of itme avaliable in the buffer (prevents consumer from removing from an empty buffer)

        - slots (init'd to 0) -> tracks the avaliable slots in the buffer (prevents producers from adding to a full buffer)

    libraries to use: 
    #include <semaphore.h>
    #include <unistd.h>

    example of producer process: 

    while(true) {
        /* produce an item */
        sem_wait(slots);
        sem_wait(mutex);

        /* add produced item to the buffer (critical section) */

        sem_post(mutex); // allows access to buffer 
        sem_post(items); // consumer will wait for this to be incremented to then access the buffer 
}

 example of consumer process: 

    while(true) {
        /* produce an item */
        sem_wait(tems);
        sem_wait(mutex);

        /* remove an item from the buffer to next_consumed */

        sem_post(mutex); 
        sem_post(slots); 

        /* consume item in the next consumed */
}

Reader-Writers Problem 
--
-shared data set 
    - readers -> only read; they do not modify 
    - writers -> can read and write

    problem:
        - multiple readers that are accessing the data simultanesouly 
        - only one writer can access the data at a time (to prevent inconsistency)

        different implementation prioritize either readers or writers to balance performance or fairness 

        ***some solutions***:
        - no reader should wait simply because a writer is waiting (favor readers)
        - a reader that arrives after a write a writer must wait, even if writer is also waiting (favors writing)

        both of these can lead to potiential starvation for a reader/writer (thread being blocked indefinitely)

Reader-writers problem - code 
--

sem_t w_mutex = 1; // writer mutex 
sem_t r_mutux = 1; // general reader mutex 
readcnt = 0; // hold the number of readers 

/* writer process */
while (true){
    sem_wait(w_mutex); // decrement 

    /* writing is performed (critical section) */

    sem_post(w_mutex); // increment 
}

/* reader process */
while (true){
    sem_wait(r_mutex);
    readcnt++;
    if (readcnt == 1) // first reader 
        sem_wait(w_mutex);
    sem_post(r_mutex);

    /* reading is performed */

    sem_wait(r_mutex);
    readcnt--;
    if (readcnt == 0); // last reader 
        sem_post(w_mutex);
    sem_post(r_mutex);
}

Dining-Philosphers Problem 
--
- trying to 

- N philosphers sit around a table sharing a bowl of rice 
- They alternate between thinking and eating 
- They do not communicate with each other 

Rules:
    - each philospher needs two chopticks to eat 
    - they pick up chopsticks one at a time and must release both after eating 

Challenges:
    - Deadlock risk: if all philsophers pick up one chopstick at the same time, no one can eat 
    - shared resource:
        - bowl of rice 
        - chopsticks (represented by semaphore)

    Algorithm:

    - semaphore as solution 

    sem_t chopstick[5]; // -> init to 1

    while(1){
        sem_wait(chopstick[i]);
        sem_wait(chopstick[i+1 % 5]);

        /* eat for a while */

        sem_post(chopstick[i]);
        sem_post(chopstick[i+1 % 5]);
        
        /* think for a while */
    }

    Problems:
        - it may lead to deadlock, each chopstick is in mutual exclusive state (no two neightbors can eat at the same time) 
        - what happens if all philosphers try to eat at the same time? 
            - solution allows for each philosphers left chopstick to be taken, which causes each philospher to be delayed indefinitely
            because the right is held by a neighbor 

    Solutions:
        - allow at most i-1 (in this example 5, so 4) philosphers to be waiting waiting at the same time while one eats 
        - allow a philospher to pick up both chopsticks only if they are both avaliable (at the same time)

        - **** asymmetic solution:
            1. an off numbers philospher picks up the left chopstick before the right 
            2. an even numbered philopsher picks up the right chopstck before the left

Semaphore (POSIX)
--
    - there are two versions: named and unnamed semaphores 
    
    - named are used by unrelated processes, the idea being that threads of processes are designed to work together or share some common 
    parent process 

    - unnamed are usually more synchronization between related processes, usually stored in memory shared between two related processes 

    POSIX unnamed semaphore: 
        - creating a semaphore:
            #include <semaphore.h>

            sem_t sem; 

            //create a semaphore and init it to 1;
            sem_init(&sem, 0, 1);

            - acquire and release semaphore 
            // acquire the semaphore 
            sem_wait(&sem);

            /* critical section */

            // release the semaphore 
            sem_post(&sem);

Exercise:

init: s=1, t=0; // binary semaphore 

Thread 1:
    wait(s);
    signal(s);
    wait(t);
    signal(t);

Thread 2:
    wait(s);
    signal(s);
    wait(t);
    signal(t); 

(a) does it deadlock? 
yes both threads get stuck at line 3

(b) assume counting semaphore: how can this be solved?
make sure we run wait(t) at different intervals (this would mean moving the wait(t) to the top for example)

Deadlock and Starvation 
--
Deadlock 
    - occurs when a set of processes are permanently waiting on events that can only be triggered by other blcoked processes
    - no efficient general solution to prevent deadlock 

System Model 
    - a system consists of resource types, each can have multiple instances 
        - resource types: R1, R2, ...., Rm 
            - memory space, CPU cycles, I/O devices 
        - each resource type Ri has Wi instnaces 
    
    - processes request, use, and release resources in a structured manner 

Resource Categories
--
- reusable - one process can use this type at a time but does not cause the resource to be depleted 
    - processors, i/o channels, main and secondary memory, devices, and data structures (files, database, and semaphores)

- consumable - one that can created (produced) and destroyed (consumed) 
    - interrupts, signals, messages, and information from i/o buffers 

Deadlock scenarios:
    reusable resource deadlock: processes request in an order that leads to the inability to proceed  

    exmaple: space is avaliable for allocation of 200Kbytes, and this occurs:

    P1:
    ...
    Request 80 Kbytes 
    ...
    Request 60 Kbytes 

    P2:
    ...
    Request 70 Kbytes 
    ...
    Request 80 Kbytes 

    Deadlock due to memory ***possible with virtual memory*** 

    Consume Resources Deadlock: Occurs when two processes try to send and recieve messages (but they end up blocking each other)

    P1:
    ...
    Recieve(P2)
    ...
    Send(P2, M1)

    P2:
    ...
    Recieve(P1)
    ...
    Send(P1, M2)

    - deadlock occurs if the recieved is blocking (the receiving process is blocked until the messages are recieved)
    - not typically common situation, sometimes takes long periods of time (up to years) before a deadlock occurs 

Resource-Allocation Graphs
--
- graph-based model that shows requests of processes and resouce dependencies
    - each process and resource is represented by a node 
    - graph edge directed from a process to a resource but not yet granted 
    - within resource node, a dot is shown for each of that resource 

- request edge (Pi -> Rj): process requests a resource 
- assign edge (Rj -> Pi): resource is allocated to a process  

Circular Wait (cycle) - no process (t1, t2, t3) can proceed, each process is waiting on a resource that is held by another process 

    Mitigation:
        - process termination (terminating t3 to allow t2 to use R3)
        - timeout 
        - suspending 

Resource-Allocation with a cycle but no deadlock 
--
- if graph contains no cycles -> no deadlock
- if graph contains a cycle 
    - if only one instance per resource type, then deadlock 
    - if several instances per resource type, then possibly deadlock 

Example of Resource-Allocation graph definiton
--
assume there are three resource types R1 with 1 instance, R2 with 3 instances, and R3 with 2 instances. There are currently 4 threads/processes 
called T1, T2, T3, and T4.

- T1 is using one instance of R3, and request one instance from R1
- T2 is using one instance of R1 and one instance of R2. It is also requesting one instance from R3. 
- T3 is using one instance from R3 and requesting one instance from R2. 
- T4 is using two instances of R2 and requesting one instance from R3 

Draw a Resource-Allocation graph and determine if at this snapshot in time is there deadlock? 
Yes, there is deadlock. Solution terminating at T1

Deadlock Characterization 
--
Four conditions for deadlock (that need to be simultaneously active)
1. mutual exclusion - only one process can use a resource at a time 
2. hold and wait - a process holds some resource while waiting for others 
3. no preemption - resources can only be released voluntarily 
4. circular wait - a circular chain for waiting processes that exists 

Methods for handling deadlock (PAD)
--
THere is not really a perfect strategy for handling deadlock 

Three common approaches (PAD):
- Deadlock Prevention - disallowing one of three necessary conditions for deadlock occurence, or prevent circular wait condition from happening 
- Deadlock Avoidance - Do not grant a resource request if allocation might lead to deadlock 
- Deadlock Detection - Grant request when possible, but periodically check for the presence of deadlock and take action to recover 

Deadlock Prevention 
--
Two main methods:
    - indirect - prevent the occurence of one of the necessary conditions 
    - direct - prevent occurence of circular wait 

conditionas of prevention:
    - mutual exlusion - cannot always prevent 
    - hold and wait - requires processes to request all resource at once (inefficent)
    - no preemption - forces processes to release resources if a request is denied 
    - circular wait - impose a linear ordering of resources 

Deadlock Avoidance 
--
- if a system is in a safe state -> no deadlock 
- if a system is in a unsafe state -> possibility of deadlock 
    - avoidance -> tries to ensure the system never ends up in the unsafe state 

Bankers algorithm 
--
- checks if granting a resource request keeps the system in a safe state 
- matrices:
    - available - resources that are not allocated but can be used for a process 
    - max - shows the maximum requirements of a process in terms of resource requirements 
    - allocation - what is currently allocated to a process 
    - need - allocation requirements that a process needs to complete 

* using these matrices to ensure the system never enters an unsafe state  

Main ideas:
1. multiple instances of resources 
2. each process must have a priority maximum claim use 
3. when a process requests a reosurce, it may have to wait 
    - waiting until another process completes/releases allocated resources 
4. when a process gets all its resources it must return them in a finite amount of time 
    - so that other processes can use them (de-allocation)

Methodology and Data structures of Bankers Algorithm
--
- n = number of processes 
- m = number of resource types 

Available: a vector of length m 
max: n*m matrix 
allocation: n*m matrix 
need: n*m -> Need[i,j]= Max[i,j] - Allocation[i,j] 

Bankers Safety Algorithm 
--
1. init 
    Work = available 
    Marked[i] = false for i = 0, 1, ..., n-1
    Generate NEED MATRIX for each process using max and current allocation 

2. Check for process' (in order of Process ID) Need <= Work and Marked = false 
    - if no process that exists where this condition is true, then go to step 4 (completion)

3. Once a process is found to satisfy step 2 condition, you now consider completed and then complete this operation -> Work = Work + Allocation_i
    - returns resources to available (work) and go back to step 2

4. System is in a safe state (a safe sequence is generated)

Example: 
5 processes: P0 - P4 
3 Resouce Types: A (10 instances), B (5 instances), C (7 instances)

Snapshot at time T0:

        Allocation      Max     Available 
        A B C           A B C   A B C 
P0      0 1 0           7 5 3   3 3 2 
P1      2 0 0           3 2 2   
P3      3 1 1           2 2 2  
P4      0 0 2           4 3 3     

What is the safe sequence? 

< P1, P3, P0, P3, P4 > -> this one of the many execution orders to achieve a safe state 

< P1, P3, P4, P0, P2 > * using loop method 

What is P1 requests (1, 0, 2)?
    we check to see what is currently in avalaible, if requests is <= what is in available, we can usually satisfy the request

Deadlock avoidance restrictions
--
- the maximum resource requirement for each process must be stated in advance 
- the process under consideration must be independent; in order which which they execute must be unconstrained by any synchronization requirements
- there must be a fixed number of resources to allocate 
- no process may exit while holding resources 

with deadlock, avoidance, the advantage is that the system tests for a safety sequence before finishing execution 
    -> prevents preemption and rollback of processes 
    -> a little less restrictive than deadlock prevention 

Deadlock Detection 
--
- allows the system to enter deadlock state 
- Algorithm 
    - runs at certain intervals 
        - can be as frequent as every time a resource is requested (or a little less frequent)
        - considered simple because it typically involves cycles in a resource-allocation graph 

- recovery schemes are used to handle deadlock once it has been detected:
    - preemption - temporarily taking away resources from processes 
    - rollback - returning processes to some safe state and restarting 
    - killing of processes - terminating one or more processes to break deadlock 

Simplified Graph (wait for graph)
    - the only nodes are processses 
    - Pi > Pj => Pi waiting for Pj 
    - it is useful if the allocation graph contains a cycle. if a cycle exists we typically have deadlock state 

    deadlock detection:
        similar to bankers, so we can solve it like bankers:
            - difference: can a request be granted without deadlock 
                - checking requests vs work (available)
                - if a request is not avalaible we will assume the process is in a deadlock state 
                - anytime a request is tested, we must "rerun" bankers 
                - if all request can be satisfied we considered the state of the system a safe state 

Detection-Algorithm Usage
--
- when and how often should we use this?
    - how often does deadlock occur?
        - if deadlocks are rare, alogorithm may run more infrequently 
        - if deadlocks are common, may need to run more often 
    
    - how many processes will need to be rollbacked (or terminated)?
        - one for each disjointed cycle (release the process -> suspend/terminated)

Recovery from deadlock 
--
- process termination - abort all deadlocked processes or one at a time 
    - in case of all,  not done simultenously but one process at a time until we get rid of deadlock cycle 
    - criteria: priority (lowest priority first), resources used, and completion time 

-resource preemption 
    - select victim process and rollback to a safe state 
        - make sure to minimize cost 
            - cost associated typically with the number of resources the deadlocked process is holding and amount of time a process has been running 
        - prevent starvation by limiting how often a process is preempted 

Deadlock strategies
--  
- deadlock precention strategies are very conservative 
    -solve the problem of deadlock by limiting access to resource and by imposing restrictions on 
    - deaclock detection strategies are he opposite 
        - do no limit resources access or process actions

Integrated Deadlock
--
the different strats for resource types:
    - swappaple space: prevent deadlocks by allocating all required resources at once 